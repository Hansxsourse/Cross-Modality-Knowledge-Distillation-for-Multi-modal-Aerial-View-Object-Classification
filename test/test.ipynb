{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "exp_num = \"test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "#     tf.set_random_seed(seed)\n",
    "\n",
    "seed = 2019\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/4uiiurz1/pytorch-auto-augment\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "\n",
    "\n",
    "class AutoAugment(object):\n",
    "    def __init__(self):\n",
    "        self.policies = [\n",
    "            ['Invert', 0.1, 7, 'Contrast', 0.2, 6],\n",
    "            ['Rotate', 0.7, 2, 'TranslateX', 0.3, 9],\n",
    "            ['Sharpness', 0.8, 1, 'Sharpness', 0.9, 3],\n",
    "            ['ShearY', 0.5, 8, 'TranslateY', 0.7, 9],\n",
    "            ['AutoContrast', 0.5, 8, 'Equalize', 0.9, 2],\n",
    "            ['ShearY', 0.2, 7, 'Posterize', 0.3, 7],\n",
    "            ['Color', 0.4, 3, 'Brightness', 0.6, 7],\n",
    "            ['Sharpness', 0.3, 9, 'Brightness', 0.7, 9],\n",
    "            ['Equalize', 0.6, 5, 'Equalize', 0.5, 1],\n",
    "            ['Contrast', 0.6, 7, 'Sharpness', 0.6, 5],\n",
    "            ['Color', 0.7, 7, 'TranslateX', 0.5, 8],\n",
    "            ['Equalize', 0.3, 7, 'AutoContrast', 0.4, 8],\n",
    "            ['TranslateY', 0.4, 3, 'Sharpness', 0.2, 6],\n",
    "            ['Brightness', 0.9, 6, 'Color', 0.2, 8],\n",
    "            ['Solarize', 0.5, 2, 'Invert', 0.0, 3],\n",
    "            ['Equalize', 0.2, 0, 'AutoContrast', 0.6, 0],\n",
    "            ['Equalize', 0.2, 8, 'Equalize', 0.6, 4],\n",
    "            ['Color', 0.9, 9, 'Equalize', 0.6, 6],\n",
    "            ['AutoContrast', 0.8, 4, 'Solarize', 0.2, 8],\n",
    "            ['Brightness', 0.1, 3, 'Color', 0.7, 0],\n",
    "            ['Solarize', 0.4, 5, 'AutoContrast', 0.9, 3],\n",
    "            ['TranslateY', 0.9, 9, 'TranslateY', 0.7, 9],\n",
    "            ['AutoContrast', 0.9, 2, 'Solarize', 0.8, 3],\n",
    "            ['Equalize', 0.8, 8, 'Invert', 0.1, 3],\n",
    "            ['TranslateY', 0.7, 9, 'AutoContrast', 0.9, 1],\n",
    "        ]\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = apply_policy(img, self.policies[random.randrange(len(self.policies))])\n",
    "        return img\n",
    "\n",
    "\n",
    "operations = {\n",
    "    'ShearX': lambda img, magnitude: shear_x(img, magnitude),\n",
    "    'ShearY': lambda img, magnitude: shear_y(img, magnitude),\n",
    "    'TranslateX': lambda img, magnitude: translate_x(img, magnitude),\n",
    "    'TranslateY': lambda img, magnitude: translate_y(img, magnitude),\n",
    "    'Rotate': lambda img, magnitude: rotate(img, magnitude),\n",
    "    'AutoContrast': lambda img, magnitude: auto_contrast(img, magnitude),\n",
    "    'Invert': lambda img, magnitude: invert(img, magnitude),\n",
    "    'Equalize': lambda img, magnitude: equalize(img, magnitude),\n",
    "    'Solarize': lambda img, magnitude: solarize(img, magnitude),\n",
    "    'Posterize': lambda img, magnitude: posterize(img, magnitude),\n",
    "    'Contrast': lambda img, magnitude: contrast(img, magnitude),\n",
    "    'Color': lambda img, magnitude: color(img, magnitude),\n",
    "    'Brightness': lambda img, magnitude: brightness(img, magnitude),\n",
    "    'Sharpness': lambda img, magnitude: sharpness(img, magnitude),\n",
    "    'Cutout': lambda img, magnitude: cutout(img, magnitude),\n",
    "}\n",
    "\n",
    "\n",
    "def apply_policy(img, policy):\n",
    "    if random.random() < policy[1]:\n",
    "        img = operations[policy[0]](img, policy[2])\n",
    "    if random.random() < policy[4]:\n",
    "        img = operations[policy[3]](img, policy[5])\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def transform_matrix_offset_center(matrix, x, y):\n",
    "    o_x = float(x) / 2 + 0.5\n",
    "    o_y = float(y) / 2 + 0.5\n",
    "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n",
    "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n",
    "    transform_matrix = offset_matrix @ matrix @ reset_matrix\n",
    "    return transform_matrix\n",
    "\n",
    "\n",
    "def shear_x(img, magnitude):\n",
    "    img = np.array(img)\n",
    "    magnitudes = np.linspace(-0.3, 0.3, 11)\n",
    "\n",
    "    transform_matrix = np.array([[1, random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]), 0],\n",
    "                                 [0, 1, 0],\n",
    "                                 [0, 0, 1]])\n",
    "    transform_matrix = transform_matrix_offset_center(transform_matrix, img.shape[0], img.shape[1])\n",
    "    affine_matrix = transform_matrix[:2, :2]\n",
    "    offset = transform_matrix[:2, 2]\n",
    "    img = np.stack([ndimage.interpolation.affine_transform(\n",
    "                    img[:, :, c],\n",
    "                    affine_matrix,\n",
    "                    offset) for c in range(img.shape[2])], axis=2)\n",
    "    img = Image.fromarray(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def shear_y(img, magnitude):\n",
    "    img = np.array(img)\n",
    "    magnitudes = np.linspace(-0.3, 0.3, 11)\n",
    "\n",
    "    transform_matrix = np.array([[1, 0, 0],\n",
    "                                 [random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]), 1, 0],\n",
    "                                 [0, 0, 1]])\n",
    "    transform_matrix = transform_matrix_offset_center(transform_matrix, img.shape[0], img.shape[1])\n",
    "    affine_matrix = transform_matrix[:2, :2]\n",
    "    offset = transform_matrix[:2, 2]\n",
    "    img = np.stack([ndimage.interpolation.affine_transform(\n",
    "                    img[:, :, c],\n",
    "                    affine_matrix,\n",
    "                    offset) for c in range(img.shape[2])], axis=2)\n",
    "    img = Image.fromarray(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def translate_x(img, magnitude):\n",
    "    img = np.array(img)\n",
    "    magnitudes = np.linspace(-150/331, 150/331, 11)\n",
    "\n",
    "    transform_matrix = np.array([[1, 0, 0],\n",
    "                                 [0, 1, img.shape[1]*random.uniform(magnitudes[magnitude], magnitudes[magnitude+1])],\n",
    "                                 [0, 0, 1]])\n",
    "    transform_matrix = transform_matrix_offset_center(transform_matrix, img.shape[0], img.shape[1])\n",
    "    affine_matrix = transform_matrix[:2, :2]\n",
    "    offset = transform_matrix[:2, 2]\n",
    "    img = np.stack([ndimage.interpolation.affine_transform(\n",
    "                    img[:, :, c],\n",
    "                    affine_matrix,\n",
    "                    offset) for c in range(img.shape[2])], axis=2)\n",
    "    img = Image.fromarray(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def translate_y(img, magnitude):\n",
    "    img = np.array(img)\n",
    "    magnitudes = np.linspace(-150/331, 150/331, 11)\n",
    "\n",
    "    transform_matrix = np.array([[1, 0, img.shape[0]*random.uniform(magnitudes[magnitude], magnitudes[magnitude+1])],\n",
    "                                 [0, 1, 0],\n",
    "                                 [0, 0, 1]])\n",
    "    transform_matrix = transform_matrix_offset_center(transform_matrix, img.shape[0], img.shape[1])\n",
    "    affine_matrix = transform_matrix[:2, :2]\n",
    "    offset = transform_matrix[:2, 2]\n",
    "    img = np.stack([ndimage.interpolation.affine_transform(\n",
    "                    img[:, :, c],\n",
    "                    affine_matrix,\n",
    "                    offset) for c in range(img.shape[2])], axis=2)\n",
    "    img = Image.fromarray(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def rotate(img, magnitude):\n",
    "    img = np.array(img)\n",
    "    magnitudes = np.linspace(-30, 30, 11)\n",
    "    theta = np.deg2rad(random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]))\n",
    "    transform_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                                 [np.sin(theta), np.cos(theta), 0],\n",
    "                                 [0, 0, 1]])\n",
    "    transform_matrix = transform_matrix_offset_center(transform_matrix, img.shape[0], img.shape[1])\n",
    "    affine_matrix = transform_matrix[:2, :2]\n",
    "    offset = transform_matrix[:2, 2]\n",
    "    img = np.stack([ndimage.interpolation.affine_transform(\n",
    "                    img[:, :, c],\n",
    "                    affine_matrix,\n",
    "                    offset) for c in range(img.shape[2])], axis=2)\n",
    "    img = Image.fromarray(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def auto_contrast(img, magnitude):\n",
    "    img = ImageOps.autocontrast(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def invert(img, magnitude):\n",
    "    img = ImageOps.invert(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def equalize(img, magnitude):\n",
    "    img = ImageOps.equalize(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def solarize(img, magnitude):\n",
    "    magnitudes = np.linspace(0, 256, 11)\n",
    "    img = ImageOps.solarize(img, random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]))\n",
    "    return img\n",
    "\n",
    "\n",
    "def posterize(img, magnitude):\n",
    "    magnitudes = np.linspace(4, 8, 11)\n",
    "    img = ImageOps.posterize(img, int(round(random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]))))\n",
    "    return img\n",
    "\n",
    "\n",
    "def contrast(img, magnitude):\n",
    "    magnitudes = np.linspace(0.1, 1.9, 11)\n",
    "    img = ImageEnhance.Contrast(img).enhance(random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]))\n",
    "    return img\n",
    "\n",
    "\n",
    "def color(img, magnitude):\n",
    "    magnitudes = np.linspace(0.1, 1.9, 11)\n",
    "    img = ImageEnhance.Color(img).enhance(random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]))\n",
    "    return img\n",
    "\n",
    "\n",
    "def brightness(img, magnitude):\n",
    "    magnitudes = np.linspace(0.1, 1.9, 11)\n",
    "    img = ImageEnhance.Brightness(img).enhance(random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]))\n",
    "    return img\n",
    "\n",
    "\n",
    "def sharpness(img, magnitude):\n",
    "    magnitudes = np.linspace(0.1, 1.9, 11)\n",
    "    img = ImageEnhance.Sharpness(img).enhance(random.uniform(magnitudes[magnitude], magnitudes[magnitude+1]))\n",
    "    return img\n",
    "\n",
    "\n",
    "def cutout(org_img, magnitude=None):\n",
    "    img = np.array(img)\n",
    "\n",
    "    magnitudes = np.linspace(0, 60/331, 11)\n",
    "\n",
    "    img = np.copy(org_img)\n",
    "    mask_val = img.mean()\n",
    "\n",
    "    if magnitude is None:\n",
    "        mask_size = 16\n",
    "    else:\n",
    "        mask_size = int(round(img.shape[0]*random.uniform(magnitudes[magnitude], magnitudes[magnitude+1])))\n",
    "    top = np.random.randint(0 - mask_size//2, img.shape[0] - mask_size)\n",
    "    left = np.random.randint(0 - mask_size//2, img.shape[1] - mask_size)\n",
    "    bottom = top + mask_size\n",
    "    right = left + mask_size\n",
    "\n",
    "    if top < 0:\n",
    "        top = 0\n",
    "    if left < 0:\n",
    "        left = 0\n",
    "\n",
    "    img[top:bottom, left:right, :].fill(mask_val)\n",
    "\n",
    "    img = Image.fromarray(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "class Cutout(object):\n",
    "    def __init__(self, length=16):\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "\n",
    "        mask_val = img.mean()\n",
    "\n",
    "        top = np.random.randint(0 - self.length//2, img.shape[0] - self.length)\n",
    "        left = np.random.randint(0 - self.length//2, img.shape[1] - self.length)\n",
    "        bottom = top + self.length\n",
    "        right = left + self.length\n",
    "\n",
    "        top = 0 if top < 0 else top\n",
    "        left = 0 if left < 0 else top\n",
    "\n",
    "        img[top:bottom, left:right, :] = mask_val\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIXUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_ = 0.4\n",
    "\n",
    "\n",
    "# def mixup_data(x, y, alpha=alpha_, use_cuda=True):\n",
    "#     if alpha > 0:\n",
    "#         lam = np.random.beta(alpha, alpha)\n",
    "#     else:\n",
    "#         lam = 1\n",
    "\n",
    "#     batch_size = x.size()[0]\n",
    "#     if use_cuda:\n",
    "#         index = torch.randperm(batch_size).cuda()\n",
    "#     else:\n",
    "#         index = torch.randperm(batch_size)\n",
    "\n",
    "#     mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "#     y_a, y_b = y, y[index]\n",
    "#     return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "#     return lam * criterion(pred.float().cuda(), y_a.float().cuda()) + (1 - lam) * criterion(pred.float().cuda(), y_b.float().cuda())\n",
    "\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "#     print(y)\n",
    "    y_a, y_b = y, y[index]\n",
    "    \n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, *datasets):\n",
    "        self.datasets = datasets\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return tuple(d[i] for d in self.datasets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(d) for d in self.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "EO_data_transforms = {\n",
    "    'Training': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize((30,30)),\n",
    "        AutoAugment(),\n",
    "        Cutout(),\n",
    "#         transforms.RandomRotation(15,),\n",
    "#         transforms.RandomResizedCrop(30),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.RandomVerticalFlip(),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.2913437], [0.12694514])\n",
    "        \n",
    "        \n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#         transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "        #transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
    "    ]),\n",
    "    'Test': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize(30),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.2913437], [0.12694514])\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#         transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "       # transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
    "    ]),\n",
    "    'valid_EO': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((30,30)),\n",
    "#         AutoAugment(),\n",
    "        \n",
    "#         transforms.RandomRotation(15,),\n",
    "#         transforms.RandomResizedCrop(48),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.2913437], [0.12694514])\n",
    "        \n",
    "#         transforms.Grayscale(num_output_channels=1),\n",
    "#         transforms.Resize(48),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.5], [0.5])\n",
    "#         transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "       # transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'Training': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((52,52)),\n",
    "        transforms.RandomRotation(15,),\n",
    "        transforms.RandomResizedCrop(48),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4062625], [0.12694514])\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#         transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "        #transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
    "    ]),\n",
    "    'Test': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize(48),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4062625], [0.12694514])\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#         transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "       # transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((52,52)),\n",
    "        transforms.RandomRotation(15,),\n",
    "        transforms.RandomResizedCrop(48),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4062625], [0.12694514])\n",
    "        \n",
    "#         transforms.Grayscale(num_output_channels=1),\n",
    "#         transforms.Resize(48),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.5], [0.5])\n",
    "#         transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "       # transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "# data_dir = '/mnt/sda1/cvpr21/Classification/ram'\n",
    "# EO_image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "#                                           EO_data_transforms[x])\n",
    "#                   for x in ['Training', 'Test']}\n",
    "# EO_dataloaders = {x: torch.utils.data.DataLoader(EO_image_datasets[x], batch_size=256,\n",
    "#                                              shuffle=True, num_workers=64, pin_memory=True)\n",
    "#               for x in ['Training', 'Test']}\n",
    "# EO_dataset_sizes = {x: len(EO_image_datasets[x]) for x in ['Training', 'Test']}\n",
    "# EO_class_names = EO_image_datasets['Training'].classes\n",
    "\n",
    "\n",
    "\n",
    "# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "#                                           data_transforms[x])\n",
    "#                   for x in ['Training', 'Test']}\n",
    "\n",
    "# combine_dataset = ConcatDataset(EO_image_datasets, image_datasets)\n",
    "# dataloaders = {x: torch.utils.data.DataLoader(combine_dataset[x], batch_size=256,\n",
    "#                                              shuffle=True, num_workers=64, pin_memory=True)\n",
    "#               for x in ['Training', 'Test']}\n",
    "# dataset_sizes = {x: len(image_datasets[x]) for x in ['Training', 'Test']}\n",
    "# class_names = image_datasets['Training'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# def imshow(inp, title=None):\n",
    "#     \"\"\"Imshow for Tensor.\"\"\"\n",
    "#     inp = inp.numpy().transpose((1, 2, 0))\n",
    "# #     mean = np.array([0.1786, 0.4739, 0.5329])\n",
    "# #     std = np.array([[0.0632, 0.1361, 0.0606]])\n",
    "# #     inp = std * inp + mean\n",
    "#     inp = np.clip(inp, 0, 1)\n",
    "#     plt.imshow(inp)\n",
    "#     if title is not None:\n",
    "#         plt.title(title)\n",
    "#     plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "    \n",
    "# # Get a batch of training data\n",
    "# EO_inputs, EO_classes = next(iter(EO_dataloaders['Training']))\n",
    "\n",
    "\n",
    "# inputs, classes, k ,_= next(iter(dataloaders))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Make a grid from batch\n",
    "# EO_out = torchvision.utils.make_grid(EO_inputs)\n",
    "\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "# imshow(EO_out, title=[EO_class_names[x] for x in classes])\n",
    "\n",
    "# imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "output_dim = 10\n",
    "\n",
    "class SAR_EO_Combine_Dataset(data.Dataset):\n",
    "    def __init__(self,df_sar,dirpath_sar,transform_sar,df_eo=None,dirpath_eo=None,transform_eo=None,test = False):\n",
    "        self.df_sar = df_sar\n",
    "        self.test = test\n",
    "        self.dirpath_sar = dirpath_sar\n",
    "        self.transform_sar = transform_sar\n",
    "        \n",
    "        self.df_eo = df_eo\n",
    "#         self.test = test\n",
    "        self.dirpath_eo = dirpath_eo\n",
    "        self.transform_eo = transform_eo\n",
    "        #image data \n",
    "#         if not self.test:\n",
    "#             self.image_arr = np.asarray(str(self.dirpath)+'/'+self.df.iloc[:, 0]+'.png')\n",
    "#         else:\n",
    "#             self.image_arr = np.asarray(str(self.dirpath)+'/'+self.df.iloc[:, 0])\n",
    "        \n",
    "#         #labels data\n",
    "#         if not self.test:\n",
    "#              self.label_df = self.df.iloc[:,1]\n",
    "        \n",
    "        # Calculate length of df\n",
    "        self.data_len = len(self.df_sar.index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name_sar = self.df_sar.img_name[idx]\n",
    "        image_name_sar = os.path.join(self.dirpath_sar, image_name_sar)\n",
    "        img_sar = Image.open(image_name_sar)#.convert('RGB')\n",
    "        img_tensor_sar = self.transform_sar(img_sar)\n",
    "        \n",
    "        image_name_eo = self.df_eo.img_name[idx]\n",
    "        image_name_eo = os.path.join(self.dirpath_eo, image_name_eo)\n",
    "        img_eo = Image.open(image_name_eo)#.convert('RGB')\n",
    "        img_tensor_eo = self.transform_eo(img_eo)\n",
    "        \n",
    "#         image_name = self.df.img_name[idx]\n",
    "#         img = Image.open(image_name)#.convert('RGB')\n",
    "#         img_tensor = self.transform(img)\n",
    "        \n",
    "        \n",
    "        if not self.test:\n",
    "            image_labels = int(self.df_sar.class_id[idx])\n",
    "#             label_tensor = torch.zeros((1, output_dim))\n",
    "#             for label in image_labels.split():\n",
    "#                 label_tensor[0, int(label)] = 1\n",
    "            image_label = torch.tensor(image_labels,dtype= torch.long)\n",
    "            image_label = image_label.squeeze()\n",
    "            \n",
    "            image_labels_eo = int(self.df_eo.class_id[idx])\n",
    "#             label_tensor_eo = torch.zeros((1, output_dim))\n",
    "#             for label_eo in image_labels_eo.split():\n",
    "#                 label_tensor_eo[0, int(label_eo)] = 1\n",
    "            image_label_eo = torch.tensor(image_labels_eo,dtype= torch.long)\n",
    "            image_label_eo = image_label_eo.squeeze()\n",
    "#             print(image_label_eo)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            return (img_tensor_sar,image_label), (img_tensor_eo, image_label_eo)\n",
    "        \n",
    "        return (img_tensor_sar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAR_EO_Combine_Dataset2(data.Dataset):\n",
    "    def __init__(self,df_sar,dirpath_sar,transform_sar,df_eo=None,dirpath_eo=None,transform_eo=None,test = False):\n",
    "        self.df_sar = df_sar\n",
    "        self.test = test\n",
    "        self.dirpath_sar = dirpath_sar\n",
    "        self.transform_sar = transform_sar\n",
    "        \n",
    "        self.df_eo = df_eo\n",
    "#         self.test = test\n",
    "        self.dirpath_eo = dirpath_eo\n",
    "        self.transform_eo = transform_eo\n",
    "        #image data \n",
    "#         if not self.test:\n",
    "#             self.image_arr = np.asarray(str(self.dirpath)+'/'+self.df.iloc[:, 0]+'.png')\n",
    "#         else:\n",
    "#             self.image_arr = np.asarray(str(self.dirpath)+'/'+self.df.iloc[:, 0])\n",
    "        \n",
    "#         #labels data\n",
    "#         if not self.test:\n",
    "#              self.label_df = self.df.iloc[:,1]\n",
    "        \n",
    "        # Calculate length of df\n",
    "        self.data_len = len(self.df_sar.index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name_sar = self.df_sar.img_name[idx]\n",
    "        image_name_sar = os.path.join(self.dirpath_sar, image_name_sar)\n",
    "        img_sar = Image.open(image_name_sar)#.convert('RGB')\n",
    "        img_tensor_sar = self.transform_sar(img_sar)\n",
    "        \n",
    "        image_name_eo = self.df_eo.img_name[idx]\n",
    "        image_name_eo = os.path.join(self.dirpath_eo, image_name_eo)\n",
    "        img_eo = Image.open(image_name_eo)#.convert('RGB')\n",
    "        img_tensor_eo = self.transform_eo(img_eo)\n",
    "        \n",
    "#         image_name = self.df.img_name[idx]\n",
    "#         img = Image.open(image_name)#.convert('RGB')\n",
    "#         img_tensor = self.transform(img)\n",
    "        \n",
    "        \n",
    "        if not self.test:\n",
    "            image_labels = int(self.df_sar.class_id[idx])\n",
    "#             label_tensor = torch.zeros((1, output_dim))\n",
    "#             for label in image_labels.split():\n",
    "#                 label_tensor[0, int(label)] = 1\n",
    "            image_label = torch.tensor(image_labels,dtype= torch.long)\n",
    "            image_label = image_label.squeeze()\n",
    "            \n",
    "            image_labels_eo = int(self.df_eo.class_id[idx])\n",
    "#             label_tensor_eo = torch.zeros((1, output_dim))\n",
    "#             for label_eo in image_labels_eo.split():\n",
    "#                 label_tensor_eo[0, int(label_eo)] = 1\n",
    "            image_label_eo = torch.tensor(image_labels_eo,dtype= torch.long)\n",
    "            image_label_eo = image_label_eo.squeeze()\n",
    "#             print(image_label_eo)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            return (img_tensor_sar,image_label), (img_tensor_eo, image_label_eo)\n",
    "        \n",
    "        return (img_tensor_sar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 826/826 [00:15<00:00, 53.29it/s]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"../KD1/resnet34_kd114.pt\")\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "class ImageData(data.Dataset):\n",
    "    def __init__(self,df,dirpath,transform,test = False):\n",
    "        self.df = df\n",
    "        self.test = test\n",
    "        self.dirpath = dirpath\n",
    "        self.conv_to_tensor = transform\n",
    "        #image data \n",
    "        if not self.test:\n",
    "            self.image_arr = np.asarray(str(self.dirpath)+'/'+self.df.iloc[:, 0]+'.png')\n",
    "        else:\n",
    "            self.image_arr = np.asarray(str(self.dirpath)+'/'+self.df.iloc[:, 0])\n",
    "        \n",
    "        #labels data\n",
    "        if not self.test:\n",
    "             self.label_df = self.df.iloc[:,1]\n",
    "        \n",
    "        # Calculate length of df\n",
    "        self.data_len = len(self.df.index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_arr[idx]\n",
    "        img = Image.open(image_name)#.convert('RGB')\n",
    "        img_tensor = self.conv_to_tensor(img)\n",
    "        if not self.test:\n",
    "            image_labels = self.label_df[idx]\n",
    "            label_tensor = torch.zeros((1, output_dim))\n",
    "            for label in image_labels.split():\n",
    "                label_tensor[0, int(label)] = 1\n",
    "            image_label = torch.tensor(label_tensor,dtype= torch.float32)\n",
    "            return (img_tensor,image_label.squeeze())\n",
    "        return (img_tensor)\n",
    "\n",
    "    \n",
    "BATCH_SIZE = 1\n",
    "test_dir = \"./data/test\" ## Change it to the test file path\n",
    "test_dir_ls = os.listdir(test_dir)\n",
    "test_dir_ls.sort()\n",
    "test_df = pd.DataFrame(test_dir_ls)\n",
    "\n",
    "test_dataset = ImageData(test_df,test_dir,EO_data_transforms[\"valid_EO\"],test = True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset,batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "output_dim = 10\n",
    "\n",
    "DISABLE_TQDM = False\n",
    "predictions = np.zeros((len(test_dataset), output_dim))\n",
    "i = 0\n",
    "for test_batch in tqdm(test_loader,disable = DISABLE_TQDM):\n",
    "    test_batch = test_batch.to(device)\n",
    "    batch_prediction = model(test_batch).detach().cpu().numpy()\n",
    "    predictions[i * BATCH_SIZE:(i+1) * BATCH_SIZE, :] = batch_prediction\n",
    "    i+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission balance for class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2121564553048015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7fad942f4610>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "predictions_tensor = torch.from_numpy(predictions)\n",
    "output_softmax = m(predictions_tensor)\n",
    "# output_softmax = output_softmax/output_softmax.sum()\n",
    "\n",
    "pred = np.argmax(predictions,axis = 1)\n",
    "\n",
    "plot_ls = []\n",
    "idx = 0\n",
    "for each_pred in pred:\n",
    "    if each_pred == 0:\n",
    "        plot_ls.append(output_softmax[idx][0].item())\n",
    "    idx+=1\n",
    "# plot_ls\n",
    "    \n",
    "\n",
    "# idx = 0\n",
    "# # print(output_softmax)\n",
    "# for i in pred:\n",
    "# #     print(predictions_tensor[idx])\n",
    "#     each_output_softmax = output_softmax[idx]/output_softmax[idx].sum()\n",
    "#     print(each_output_softmax)\n",
    "#     if i == 0:\n",
    "#         new_list = set(predictions[idx])\n",
    "#         new_list.remove(max(new_list))\n",
    "#         index = predictions[idx].tolist().index(max(new_list))\n",
    "# #         index = predictions[idx].index()\n",
    "# #         print(index)\n",
    "\n",
    "        \n",
    "#     idx+=1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "   \n",
    "plt.hist(plot_ls, bins=80, histtype=\"stepfilled\", alpha=.8)\n",
    "plot_ls.sort()\n",
    "val = plot_ls[-85]\n",
    "print(val)\n",
    "plt.vlines(val, ymin = 0, ymax = 22, colors = 'r')\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\n"
     ]
    }
   ],
   "source": [
    "# print(output_softmax)\n",
    "idx = 0\n",
    "counter = 0\n",
    "for i in pred:\n",
    "#     print(predictions_tensor[idx])\n",
    "#     each_output_softmax = output_softmax[idx]/output_softmax[idx].sum()\n",
    "#     print(each_output_softmax)\n",
    "    if i == 0 and output_softmax[idx][0] < val:\n",
    "        \n",
    "        new_list = set(predictions[idx])\n",
    "        new_list.remove(max(new_list))\n",
    "        index = predictions[idx].tolist().index(max(new_list))\n",
    "#         index = predictions[idx].index()\n",
    "#         print(index)\n",
    "        pred[idx] = index\n",
    "        output_softmax[idx][0] = -100.0\n",
    "        counter += 1\n",
    "    \n",
    "\n",
    "        \n",
    "    idx+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission balance for class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21454049970403302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7fad94296bb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN70lEQVR4nO3df4xlZX3H8fenLKZWbFy6A26Q7VpKbWkrix1XW6jBos1CQoAUU2mDm5RmbStEEk1K/MPaNG38o2oTUrWrEvcPqyEFBCzakq2WbETqQBaELhZrKAU37KKtgGmsu3z7xxzqsu7sPffnzDzzfiU3954f95zvM2fyuSfnPue5qSokSW35seUuQJI0eYa7JDXIcJekBhnuktQgw12SGrRuljvbsGFDbd68eZa7lKRV7957732qquaGec9Mw33z5s0sLCzMcpeStOol+Y9h3+NlGUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatBM71Adx8XX73nB9O3XnLdMlUjSyueZuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lq0MBwT/LjSf4lyf1JHkryp938k5PcmeSR7nn99MuVJPXR58z9+8BvVNXZwBZgW5LXA9cBu6vqTGB3Ny1JWgEGhnsterabPLF7FHAJsKubvwu4dBoFSpKG1+uae5ITkuwFDgB3VtU9wKlVtR+gez5lalVKkobSK9yr6nBVbQFeAWxN8kt9d5BkR5KFJAsHDx4csUxJ0jCG6i1TVf8NfAnYBjyZZCNA93xgiffsrKr5qpqfm5sbr1pJUi99esvMJXlZ9/rFwJuAh4HbgO3datuBW6dUoyRpSOt6rLMR2JXkBBY/DG6sqs8luRu4MclVwGPAW6ZYpyRpCAPDvaoeAM45xvxvAxdMoyhJ0ni8Q1WSGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBg0M9ySnJ/likn1JHkryzm7++5I8kWRv97ho+uVKkvpY12OdQ8C7quq+JC8F7k1yZ7fsQ1X1l9MrT5I0ioHhXlX7gf3d62eS7ANOm3ZhkqTRDXXNPclm4Bzgnm7W1UkeSHJDkvVLvGdHkoUkCwcPHhyvWklSL73DPclJwE3AtVX1NPAR4AxgC4tn9h841vuqamdVzVfV/Nzc3PgVS5IG6hXuSU5kMdg/VVU3A1TVk1V1uKqeAz4GbJ1emZKkYfTpLRPgE8C+qvrgEfM3HrHaZcCDky9PkjSKPr1lzgWuBL6WZG837z3AFUm2AAU8Crx9CvVJkkbQp7fMHiDHWHTH5MuRJE2Cd6hKUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHBvzfnnLz4krWmGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBA8M9yelJvphkX5KHkryzm39ykjuTPNI9r59+uZKkPvqcuR8C3lVVvwC8HnhHkrOA64DdVXUmsLubliStAAPDvar2V9V93etngH3AacAlwK5utV3ApVOqUZI0pHXDrJxkM3AOcA9walXth8UPgCSnLPGeHcAOgE2bNo1V7PFcfP2eF0zffs15U9uXJK10vb9QTXIScBNwbVU93fd9VbWzquaran5ubm6UGiVJQ+oV7klOZDHYP1VVN3ezn0yysVu+ETgwnRIlScPq01smwCeAfVX1wSMW3QZs715vB26dfHmSpFH0ueZ+LnAl8LUke7t57wHeD9yY5CrgMeAtU6lQkjS0geFeVXuALLH4gsmWI0maBO9QlaQGDdUVciU5uuujJOmHPHOXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatDAcE9yQ5IDSR48Yt77kjyRZG/3uGi6ZUqShtHnzP2TwLZjzP9QVW3pHndMtixJ0jgGhntV3QV8Zwa1SJImZJxr7lcneaC7bLN+qZWS7EiykGTh4MGDY+xOktTXqOH+EeAMYAuwH/jAUitW1c6qmq+q+bm5uRF3J0kaxkjhXlVPVtXhqnoO+BiwdbJlSZLGMVK4J9l4xORlwINLrStJmr11g1ZI8mngfGBDkseBPwHOT7IFKOBR4O3TK1GSNKyB4V5VVxxj9iemUIskaUK8Q1WSGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lq0MDfUG3BxdfvecH07dect0yVSNJseOYuSQ0y3CWpQQPDPckNSQ4kefCIeScnuTPJI93z+umWKUkaRp8z908C246adx2wu6rOBHZ305KkFWJguFfVXcB3jpp9CbCre70LuHSyZUmSxjHqNfdTq2o/QPd8ylIrJtmRZCHJwsGDB0fcnSRpGFP/QrWqdlbVfFXNz83NTXt3kiRGD/cnk2wE6J4PTK4kSdK4Rg3324Dt3evtwK2TKUeSNAl9ukJ+GrgbeFWSx5NcBbwfeHOSR4A3d9OSpBVi4PADVXXFEosumHAtkqQJ8Q5VSWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBg0cFXK1uvj6Pb2X3X7NeUMtH2a/x9v2MNudtHHaKGnl88xdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KCxbmJK8ijwDHAYOFRV85MoSpI0nkncofrGqnpqAtuRJE2Il2UkqUHjnrkX8I9JCvibqtp59ApJdgA7ADZt2jTm7taWWY7/slLGvJE0GeOeuZ9bVa8BLgTekeQNR69QVTurar6q5ufm5sbcnSSpj7HCvaq+1T0fAG4Btk6iKEnSeEYO9yQvSfLS518Dvwk8OKnCJEmjG+ea+6nALUme387fVtUXJlKVJGksI4d7VX0TOHuCtUiSJsSukJLUoGZ/Zm8Yx/tJvj7LZ+V4XSOfX/YXT3wXgF+eXVmSViDP3CWpQYa7JDXIcJekBhnuktQgw12SGmRvmWW0XAODTXvbk2zHLP9Gq6GOcYzbBgeXW108c5ekBhnuktQgw12SGmS4S1KDDHdJapC9ZaZsmF4qw/ZomVYPmOXs/TLLcXyO1/tj2PGGjjXOz1LbHmZbwxrn7zdOHePsd9y/j714js0zd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgu0I2apJdCsftonm87mnT7Lo3zW6ok37/SnS8Ns1yILppbmvQ/8zxuriOs61Z8MxdkhpkuEtSg8YK9yTbknw9yTeSXDepoiRJ4xk53JOcAPw1cCFwFnBFkrMmVZgkaXTjnLlvBb5RVd+sqv8FPgNcMpmyJEnjSFWN9sbkcmBbVf1+N30l8Lqquvqo9XYAO7rJVwFfH73c/7cBeGoC21mNbPvaZNvXpufb/tNVNTfMG8fpCpljzPuRT4qq2gnsHGM/P7rjZKGq5ie5zdXCttv2tca2j9b2cS7LPA6cfsT0K4BvjbE9SdKEjBPuXwXOTPLKJC8C3grcNpmyJEnjGPmyTFUdSnI18A/ACcANVfXQxCo7vole5lllbPvaZNvXppHbPvIXqpKklcs7VCWpQYa7JDVoxYb7oKENkvx8kruTfD/Ju5ejxmnp0fbfTfJA9/hykrOXo85p6dH+S7q2702ykKSZX0XuO6RHktcmOdzdb9KEHsf9/CTf7Y773iTvXY46p6HPce/avzfJQ0n+eeBGq2rFPVj8gvbfgZ8BXgTcD5x11DqnAK8F/hx493LXPOO2/xqwvnt9IXDPctc94/afxA+/L3o18PBy1z2rth+x3j8BdwCXL3fdMzzu5wOfW+5al6ntLwP+FdjUTZ8yaLsr9cx94NAGVXWgqr4K/GA5CpyiPm3/clX9Vzf5FRbvMWhFn/Y/W91/OPASjnHz3CrVd0iPa4CbgAOzLG7K1vJwJn3a/jvAzVX1GCzm36CNrtRwPw34zyOmH+/mrQXDtv0q4PNTrWi2erU/yWVJHgb+Hvi9GdU2bQPbnuQ04DLgozOsaxb6/t//apL7k3w+yS/OprSp69P2nwPWJ/lSknuTvG3QRlfqLzH1GtqgUb3bnuSNLIZ7M9ec6T+sxS3ALUneAPwZ8KZpFzYDfdr+V8AfV9Xh5Firr1p92n4fi2OsPJvkIuCzwJnTLmwG+rR9HfArwAXAi4G7k3ylqv5tqY2u1HBfy0Mb9Gp7klcDHwcurKpvz6i2WRjq2FfVXUnOSLKhqlb74FJ92j4PfKYL9g3ARUkOVdVnZ1Lh9Axse1U9fcTrO5J8eA0d98eBp6rqe8D3ktwFnA0sGe4r9bLMWh7aYGDbk2wCbgauPN4n9yrVp/0/my7dkryGxS+hWviAG9j2qnplVW2uqs3A3wF/1ECwQ7/j/vIjjvtWFvNrTRx34Fbg15OsS/ITwOuAfcfb6Io8c68lhjZI8gfd8o8meTmwAPwk8FySa1n8hvnppba7GvRpO/Be4KeAD3f/64eqkVHzerb/t4C3JfkB8D/Abx/xBeuq1bPtTerZ9suBP0xyiMXj/ta1ctyral+SLwAPAM8BH6+qB4+3XYcfkKQGrdTLMpKkMRjuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUH/B5eH5aIRun/2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_ls = []\n",
    "idx = 0\n",
    "for each_pred in pred:\n",
    "    if each_pred == 1:\n",
    "        plot_ls.append(output_softmax[idx][1].item())\n",
    "    idx+=1\n",
    "# plot_ls\n",
    "    \n",
    "\n",
    "# idx = 0\n",
    "# # print(output_softmax)\n",
    "# for i in pred:\n",
    "# #     print(predictions_tensor[idx])\n",
    "#     each_output_softmax = output_softmax[idx]/output_softmax[idx].sum()\n",
    "#     print(each_output_softmax)\n",
    "#     if i == 0:\n",
    "#         new_list = set(predictions[idx])\n",
    "#         new_list.remove(max(new_list))\n",
    "#         index = predictions[idx].tolist().index(max(new_list))\n",
    "# #         index = predictions[idx].index()\n",
    "# #         print(index)\n",
    "\n",
    "        \n",
    "#     idx+=1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "   \n",
    "plt.hist(plot_ls, bins=80, histtype=\"stepfilled\", alpha=.8)\n",
    "plot_ls.sort()\n",
    "val = plot_ls[-85]\n",
    "print(val)\n",
    "plt.vlines(val, ymin = 0, ymax = 22, colors = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n"
     ]
    }
   ],
   "source": [
    "# print(output_softmax)\n",
    "idx = 0\n",
    "counter = 0\n",
    "for i in pred:\n",
    "#     print(predictions_tensor[idx])\n",
    "#     each_output_softmax = output_softmax[idx]/output_softmax[idx].sum()\n",
    "#     print(each_output_softmax)\n",
    "    if i == 1 and output_softmax[idx][1] < val:\n",
    "        new_list = set(output_softmax[idx])\n",
    "        new_list.remove(max(new_list))\n",
    "        index = output_softmax[idx].tolist().index(max(new_list))\n",
    "#         index = predictions[idx].index()\n",
    "#         print(index)\n",
    "        pred[idx] = index\n",
    "        output_softmax[idx][1] = -100.0\n",
    "        counter += 1\n",
    "    \n",
    "\n",
    "        \n",
    "    idx+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission balance for class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11162966531637959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7fad941f5e80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plot_ls = []\n",
    "idx = 0\n",
    "for each_pred in pred:\n",
    "    if each_pred == 2:\n",
    "        plot_ls.append(output_softmax[idx][2].item())\n",
    "    idx+=1\n",
    "# plot_ls\n",
    "    \n",
    "\n",
    "# idx = 0\n",
    "# # print(output_softmax)\n",
    "# for i in pred:\n",
    "# #     print(predictions_tensor[idx])\n",
    "#     each_output_softmax = output_softmax[idx]/output_softmax[idx].sum()\n",
    "#     print(each_output_softmax)\n",
    "#     if i == 0:\n",
    "#         new_list = set(predictions[idx])\n",
    "#         new_list.remove(max(new_list))\n",
    "#         index = predictions[idx].tolist().index(max(new_list))\n",
    "# #         index = predictions[idx].index()\n",
    "# #         print(index)\n",
    "\n",
    "        \n",
    "#     idx+=1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "   \n",
    "plt.hist(plot_ls, bins=80, histtype=\"stepfilled\", alpha=.8)\n",
    "plot_ls.sort()\n",
    "val = plot_ls[-85]\n",
    "print(val)\n",
    "plt.vlines(val, ymin = 0, ymax = 22, colors = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "#  print(output_softmax)\n",
    "idx = 0\n",
    "counter = 0\n",
    "for i in pred:\n",
    "#     print(predictions_tensor[idx])\n",
    "#     each_output_softmax = output_softmax[idx]/output_softmax[idx].sum()\n",
    "#     print(each_output_softmax)\n",
    "    if i == 2 and output_softmax[idx][2] < val:\n",
    "        new_list = set(output_softmax[idx])\n",
    "        new_list.remove(max(new_list))\n",
    "        index = output_softmax[idx].tolist().index(max(new_list))\n",
    "#         index = predictions[idx].index()\n",
    "#         print(index)\n",
    "        pred[idx] = index\n",
    "        output_softmax[idx][2] = -100.0\n",
    "        counter += 1\n",
    "    \n",
    "\n",
    "        \n",
    "    idx+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission balance for class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09716976256894183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7fad941d4eb0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_ls = []\n",
    "idx = 0\n",
    "for each_pred in pred:\n",
    "    if each_pred == 3:\n",
    "        plot_ls.append(output_softmax[idx][3].item())\n",
    "    idx+=1\n",
    "# plot_ls\n",
    "    \n",
    "\n",
    "# idx = 0\n",
    "# # print(output_softmax)\n",
    "# for i in pred:\n",
    "# #     print(predictions_tensor[idx])\n",
    "#     each_output_softmax = output_softmax[idx]/output_softmax[idx].sum()\n",
    "#     print(each_output_softmax)\n",
    "#     if i == 0:\n",
    "#         new_list = set(predictions[idx])\n",
    "#         new_list.remove(max(new_list))\n",
    "#         index = predictions[idx].tolist().index(max(new_list))\n",
    "# #         index = predictions[idx].index()\n",
    "# #         print(index)\n",
    "\n",
    "        \n",
    "#     idx+=1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "   \n",
    "plt.hist(plot_ls, bins=80, histtype=\"stepfilled\", alpha=.8)\n",
    "plot_ls.sort()\n",
    "val = plot_ls[-85]\n",
    "print(val)\n",
    "plt.vlines(val, ymin = 0, ymax = 22, colors = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "#  print(output_softmax)\n",
    "idx = 0\n",
    "counter = 0\n",
    "for i in pred:\n",
    "#     print(predictions_tensor[idx])\n",
    "#     each_output_softmax = output_softmax[idx]/output_softmax[idx].sum()\n",
    "#     print(each_output_softmax)\n",
    "    if i == 3 and output_softmax[idx][3] < val:\n",
    "        new_list = set(output_softmax[idx])\n",
    "        new_list.remove(max(new_list))\n",
    "        index = output_softmax[idx].tolist().index(max(new_list))\n",
    "#         index = predictions[idx].index()\n",
    "#         print(index)\n",
    "        pred[idx] = index\n",
    "        output_softmax[idx][3] = -100.0\n",
    "        counter += 1\n",
    "    \n",
    "\n",
    "        \n",
    "    idx+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [5],\n",
       " [5],\n",
       " [4],\n",
       " [5],\n",
       " [1],\n",
       " [8],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [3],\n",
       " [5],\n",
       " [5],\n",
       " [0],\n",
       " [3],\n",
       " [4],\n",
       " [3],\n",
       " [8],\n",
       " [4],\n",
       " [3],\n",
       " [2],\n",
       " [0],\n",
       " [3],\n",
       " [3],\n",
       " [0],\n",
       " [4],\n",
       " [2],\n",
       " [5],\n",
       " [3],\n",
       " [1],\n",
       " [4],\n",
       " [5],\n",
       " [5],\n",
       " [6],\n",
       " [7],\n",
       " [5],\n",
       " [2],\n",
       " [7],\n",
       " [5],\n",
       " [3],\n",
       " [5],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [5],\n",
       " [0],\n",
       " [3],\n",
       " [2],\n",
       " [0],\n",
       " [5],\n",
       " [0],\n",
       " [4],\n",
       " [5],\n",
       " [7],\n",
       " [2],\n",
       " [5],\n",
       " [5],\n",
       " [1],\n",
       " [7],\n",
       " [2],\n",
       " [2],\n",
       " [1],\n",
       " [2],\n",
       " [1],\n",
       " [4],\n",
       " [0],\n",
       " [0],\n",
       " [7],\n",
       " [1],\n",
       " [6],\n",
       " [1],\n",
       " [2],\n",
       " [4],\n",
       " [4],\n",
       " [1],\n",
       " [0],\n",
       " [6],\n",
       " [4],\n",
       " [0],\n",
       " [1],\n",
       " [3],\n",
       " [5],\n",
       " [4],\n",
       " [4],\n",
       " [4],\n",
       " [0],\n",
       " [4],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [6],\n",
       " [5],\n",
       " [6],\n",
       " [4],\n",
       " [5],\n",
       " [7],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [2],\n",
       " [2],\n",
       " [5],\n",
       " [2],\n",
       " [1],\n",
       " [4],\n",
       " [2],\n",
       " [0],\n",
       " [3],\n",
       " [4],\n",
       " [4],\n",
       " [3],\n",
       " [2],\n",
       " [3],\n",
       " [5],\n",
       " [4],\n",
       " [5],\n",
       " [8],\n",
       " [4],\n",
       " [0],\n",
       " [4],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [5],\n",
       " [5],\n",
       " [4],\n",
       " [5],\n",
       " [0],\n",
       " [3],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [4],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [3],\n",
       " [1],\n",
       " [0],\n",
       " [3],\n",
       " [2],\n",
       " [4],\n",
       " [4],\n",
       " [1],\n",
       " [6],\n",
       " [5],\n",
       " [5],\n",
       " [1],\n",
       " [0],\n",
       " [5],\n",
       " [5],\n",
       " [9],\n",
       " [0],\n",
       " [6],\n",
       " [4],\n",
       " [1],\n",
       " [3],\n",
       " [4],\n",
       " [3],\n",
       " [4],\n",
       " [4],\n",
       " [3],\n",
       " [0],\n",
       " [5],\n",
       " [7],\n",
       " [5],\n",
       " [4],\n",
       " [2],\n",
       " [0],\n",
       " [0],\n",
       " [6],\n",
       " [0],\n",
       " [2],\n",
       " [0],\n",
       " [4],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [7],\n",
       " [2],\n",
       " [4],\n",
       " [5],\n",
       " [5],\n",
       " [0],\n",
       " [7],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [4],\n",
       " [1],\n",
       " [7],\n",
       " [4],\n",
       " [0],\n",
       " [2],\n",
       " [0],\n",
       " [5],\n",
       " [5],\n",
       " [7],\n",
       " [3],\n",
       " [5],\n",
       " [1],\n",
       " [7],\n",
       " [0],\n",
       " [1],\n",
       " [5],\n",
       " [5],\n",
       " [1],\n",
       " [2],\n",
       " [1],\n",
       " [1],\n",
       " [3],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [1],\n",
       " [7],\n",
       " [7],\n",
       " [5],\n",
       " [7],\n",
       " [5],\n",
       " [7],\n",
       " [7],\n",
       " [4],\n",
       " [7],\n",
       " [1],\n",
       " [1],\n",
       " [2],\n",
       " [7],\n",
       " [0],\n",
       " [3],\n",
       " [0],\n",
       " [5],\n",
       " [5],\n",
       " [4],\n",
       " [4],\n",
       " [0],\n",
       " [0],\n",
       " [7],\n",
       " [4],\n",
       " [0],\n",
       " [2],\n",
       " [1],\n",
       " [0],\n",
       " [4],\n",
       " [4],\n",
       " [1],\n",
       " [7],\n",
       " [4],\n",
       " [7],\n",
       " [4],\n",
       " [7],\n",
       " [7],\n",
       " [5],\n",
       " [8],\n",
       " [7],\n",
       " [2],\n",
       " [5],\n",
       " [0],\n",
       " [9],\n",
       " [7],\n",
       " [5],\n",
       " [7],\n",
       " [5],\n",
       " [7],\n",
       " [4],\n",
       " [5],\n",
       " [0],\n",
       " [5],\n",
       " [5],\n",
       " [2],\n",
       " [4],\n",
       " [5],\n",
       " [4],\n",
       " [3],\n",
       " [3],\n",
       " [5],\n",
       " [3],\n",
       " [5],\n",
       " [3],\n",
       " [7],\n",
       " [4],\n",
       " [5],\n",
       " [5],\n",
       " [2],\n",
       " [7],\n",
       " [3],\n",
       " [7],\n",
       " [8],\n",
       " [4],\n",
       " [2],\n",
       " [0],\n",
       " [5],\n",
       " [4],\n",
       " [1],\n",
       " [4],\n",
       " [0],\n",
       " [4],\n",
       " [0],\n",
       " [3],\n",
       " [3],\n",
       " [1],\n",
       " [5],\n",
       " [5],\n",
       " [7],\n",
       " [4],\n",
       " [4],\n",
       " [7],\n",
       " [7],\n",
       " [3],\n",
       " [4],\n",
       " [5],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [1],\n",
       " [4],\n",
       " [0],\n",
       " [1],\n",
       " [3],\n",
       " [4],\n",
       " [7],\n",
       " [0],\n",
       " [1],\n",
       " [7],\n",
       " [7],\n",
       " [4],\n",
       " [7],\n",
       " [0],\n",
       " [2],\n",
       " [7],\n",
       " [1],\n",
       " [5],\n",
       " [7],\n",
       " [3],\n",
       " [1],\n",
       " [4],\n",
       " [0],\n",
       " [6],\n",
       " [1],\n",
       " [4],\n",
       " [3],\n",
       " [5],\n",
       " [4],\n",
       " [3],\n",
       " [8],\n",
       " [1],\n",
       " [0],\n",
       " [2],\n",
       " [0],\n",
       " [7],\n",
       " [0],\n",
       " [2],\n",
       " [1],\n",
       " [4],\n",
       " [4],\n",
       " [2],\n",
       " [7],\n",
       " [1],\n",
       " [5],\n",
       " [1],\n",
       " [2],\n",
       " [5],\n",
       " [5],\n",
       " [2],\n",
       " [1],\n",
       " [7],\n",
       " [1],\n",
       " [5],\n",
       " [7],\n",
       " [0],\n",
       " [5],\n",
       " [1],\n",
       " [7],\n",
       " [7],\n",
       " [5],\n",
       " [1],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [1],\n",
       " [5],\n",
       " [5],\n",
       " [0],\n",
       " [0],\n",
       " [4],\n",
       " [0],\n",
       " [0],\n",
       " [8],\n",
       " [2],\n",
       " [4],\n",
       " [1],\n",
       " [3],\n",
       " [7],\n",
       " [7],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [2],\n",
       " [7],\n",
       " [7],\n",
       " [1],\n",
       " [5],\n",
       " [7],\n",
       " [5],\n",
       " [3],\n",
       " [4],\n",
       " [0],\n",
       " [3],\n",
       " [1],\n",
       " [7],\n",
       " [7],\n",
       " [3],\n",
       " [0],\n",
       " [0],\n",
       " [3],\n",
       " [4],\n",
       " [2],\n",
       " [3],\n",
       " [4],\n",
       " [7],\n",
       " [8],\n",
       " [3],\n",
       " [4],\n",
       " [2],\n",
       " [1],\n",
       " [7],\n",
       " [9],\n",
       " [7],\n",
       " [3],\n",
       " [7],\n",
       " [0],\n",
       " [1],\n",
       " [2],\n",
       " [2],\n",
       " [7],\n",
       " [2],\n",
       " [4],\n",
       " [7],\n",
       " [2],\n",
       " [2],\n",
       " [1],\n",
       " [1],\n",
       " [4],\n",
       " [1],\n",
       " [2],\n",
       " [4],\n",
       " [3],\n",
       " [2],\n",
       " [2],\n",
       " [3],\n",
       " [4],\n",
       " [2],\n",
       " [4],\n",
       " [2],\n",
       " [2],\n",
       " [3],\n",
       " [2],\n",
       " [5],\n",
       " [6],\n",
       " [2],\n",
       " [2],\n",
       " [3],\n",
       " [0],\n",
       " [5],\n",
       " [4],\n",
       " [2],\n",
       " [2],\n",
       " [0],\n",
       " [1],\n",
       " [5],\n",
       " [2],\n",
       " [0],\n",
       " [0],\n",
       " [2],\n",
       " [7],\n",
       " [2],\n",
       " [2],\n",
       " [4],\n",
       " [0],\n",
       " [4],\n",
       " [4],\n",
       " [4],\n",
       " [6],\n",
       " [0],\n",
       " [2],\n",
       " [7],\n",
       " [7],\n",
       " [4],\n",
       " [3],\n",
       " [0],\n",
       " [2],\n",
       " [4],\n",
       " [4],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [7],\n",
       " [5],\n",
       " [5],\n",
       " [4],\n",
       " [5],\n",
       " [3],\n",
       " [5],\n",
       " [7],\n",
       " [0],\n",
       " [7],\n",
       " [3],\n",
       " [2],\n",
       " [7],\n",
       " [0],\n",
       " [4],\n",
       " [4],\n",
       " [7],\n",
       " [4],\n",
       " [5],\n",
       " [4],\n",
       " [2],\n",
       " [7],\n",
       " [1],\n",
       " [2],\n",
       " [0],\n",
       " [1],\n",
       " [6],\n",
       " [1],\n",
       " [4],\n",
       " [2],\n",
       " [0],\n",
       " [5],\n",
       " [3],\n",
       " [7],\n",
       " [1],\n",
       " [5],\n",
       " [7],\n",
       " [0],\n",
       " [5],\n",
       " [7],\n",
       " [2],\n",
       " [4],\n",
       " [3],\n",
       " [5],\n",
       " [4],\n",
       " [7],\n",
       " [1],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [3],\n",
       " [3],\n",
       " [3],\n",
       " [7],\n",
       " [4],\n",
       " [3],\n",
       " [0],\n",
       " [5],\n",
       " [7],\n",
       " [7],\n",
       " [6],\n",
       " [1],\n",
       " [7],\n",
       " [4],\n",
       " [1],\n",
       " [4],\n",
       " [1],\n",
       " [6],\n",
       " [1],\n",
       " [1],\n",
       " [4],\n",
       " [3],\n",
       " [7],\n",
       " [0],\n",
       " [1],\n",
       " [3],\n",
       " [7],\n",
       " [7],\n",
       " [3],\n",
       " [5],\n",
       " [4],\n",
       " [4],\n",
       " [0],\n",
       " [8],\n",
       " [5],\n",
       " [2],\n",
       " [2],\n",
       " [0],\n",
       " [1],\n",
       " [4],\n",
       " [2],\n",
       " [4],\n",
       " [2],\n",
       " [2],\n",
       " [3],\n",
       " [4],\n",
       " [4],\n",
       " [4],\n",
       " [7],\n",
       " [5],\n",
       " [1],\n",
       " [1],\n",
       " [7],\n",
       " [3],\n",
       " [1],\n",
       " [8],\n",
       " [1],\n",
       " [4],\n",
       " [2],\n",
       " [0],\n",
       " [2],\n",
       " [5],\n",
       " [7],\n",
       " [3],\n",
       " [4],\n",
       " [8],\n",
       " [4],\n",
       " [1],\n",
       " [6],\n",
       " [7],\n",
       " [1],\n",
       " [1],\n",
       " [7],\n",
       " [0],\n",
       " [4],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [7],\n",
       " [4],\n",
       " [1],\n",
       " [2],\n",
       " [2],\n",
       " [5],\n",
       " [7],\n",
       " [0],\n",
       " [0],\n",
       " [8],\n",
       " [7],\n",
       " [3],\n",
       " [1],\n",
       " [5],\n",
       " [6],\n",
       " [4],\n",
       " [4],\n",
       " [2],\n",
       " [7],\n",
       " [8],\n",
       " [0],\n",
       " [2],\n",
       " [5],\n",
       " [7],\n",
       " [4],\n",
       " [9],\n",
       " [4],\n",
       " [7],\n",
       " [0],\n",
       " [2],\n",
       " [3],\n",
       " [1],\n",
       " [3],\n",
       " [2],\n",
       " [7],\n",
       " [4],\n",
       " [2],\n",
       " [2],\n",
       " [5],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [3],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [5],\n",
       " [0],\n",
       " [3],\n",
       " [7],\n",
       " [3],\n",
       " [7],\n",
       " [4],\n",
       " [7],\n",
       " [0],\n",
       " [4],\n",
       " [5],\n",
       " [5],\n",
       " [4],\n",
       " [7],\n",
       " [1],\n",
       " [2],\n",
       " [7],\n",
       " [2],\n",
       " [5],\n",
       " [3],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [2],\n",
       " [1],\n",
       " [4],\n",
       " [3],\n",
       " [5],\n",
       " [0],\n",
       " [1],\n",
       " [5],\n",
       " [1],\n",
       " [4],\n",
       " [1],\n",
       " [3],\n",
       " [2],\n",
       " [1],\n",
       " [2],\n",
       " [0],\n",
       " [6],\n",
       " [2],\n",
       " [5],\n",
       " [3],\n",
       " [4],\n",
       " [4],\n",
       " [1],\n",
       " [0],\n",
       " [3],\n",
       " [0],\n",
       " [5],\n",
       " [8],\n",
       " [2],\n",
       " [4],\n",
       " [1],\n",
       " [0],\n",
       " [4],\n",
       " [6],\n",
       " [5],\n",
       " [4],\n",
       " [8],\n",
       " [4],\n",
       " [3],\n",
       " [5],\n",
       " [3],\n",
       " [2],\n",
       " [5],\n",
       " [4],\n",
       " [5],\n",
       " [8],\n",
       " [4],\n",
       " [3],\n",
       " [4],\n",
       " [3],\n",
       " [5],\n",
       " [3],\n",
       " [2],\n",
       " [3],\n",
       " [5],\n",
       " [1],\n",
       " [2],\n",
       " [0],\n",
       " [5],\n",
       " [2],\n",
       " [4],\n",
       " [5],\n",
       " [5],\n",
       " [1],\n",
       " [5],\n",
       " [2],\n",
       " [5],\n",
       " [7],\n",
       " [5],\n",
       " [0],\n",
       " [5],\n",
       " [8],\n",
       " [5],\n",
       " [3],\n",
       " [3],\n",
       " [9],\n",
       " [0],\n",
       " [1],\n",
       " [5],\n",
       " [5],\n",
       " [6],\n",
       " [0],\n",
       " [0],\n",
       " [2],\n",
       " [5],\n",
       " [3],\n",
       " [3],\n",
       " [5],\n",
       " [5],\n",
       " [7],\n",
       " [1],\n",
       " [6],\n",
       " [5],\n",
       " [5],\n",
       " [2],\n",
       " [4],\n",
       " [5],\n",
       " [5],\n",
       " [4],\n",
       " [2],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [4],\n",
       " [4],\n",
       " [1],\n",
       " [0],\n",
       " [4],\n",
       " [3],\n",
       " [3],\n",
       " [0],\n",
       " [4],\n",
       " [5],\n",
       " [3],\n",
       " [4],\n",
       " [2],\n",
       " [5],\n",
       " [8],\n",
       " [0],\n",
       " [7],\n",
       " [1],\n",
       " [5],\n",
       " [4],\n",
       " [6]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred = np.argmax(predictions,axis = 1)\n",
    "pred_list = []\n",
    "for i in range(len(pred)):\n",
    "    result = [pred[i]]\n",
    "    pred_list.append(result)\n",
    "pred_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EO_100578</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EO_10079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EO_102385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EO_10264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EO_103494</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>EO_93885</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>EO_95890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>EO_96662</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>EO_97302</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>EO_99431</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>826 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id class_id\n",
       "0    EO_100578        2\n",
       "1     EO_10079        1\n",
       "2    EO_102385        0\n",
       "3     EO_10264        0\n",
       "4    EO_103494        5\n",
       "..         ...      ...\n",
       "821   EO_93885        7\n",
       "822   EO_95890        1\n",
       "823   EO_96662        5\n",
       "824   EO_97302        4\n",
       "825   EO_99431        6\n",
       "\n",
       "[826 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_idx = pred_list\n",
    "\n",
    "test_df['class_id'] = predicted_class_idx\n",
    "test_df['class_id'] = test_df['class_id'].apply(lambda x : ' '.join(map(str,list(x))))\n",
    "test_df = test_df.rename(columns={0: 'image_id'})\n",
    "test_df['image_id'] = test_df['image_id'].apply(lambda x : x.split('.')[0])\n",
    "test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (idx, row) in test_df.iterrows():\n",
    "    row.image_id = row.image_id.split(\"_\")[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "103\n",
      "95\n",
      "85\n",
      "132\n",
      "135\n",
      "21\n",
      "119\n",
      "18\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    i = 0\n",
    "    for (idx, row) in test_df.iterrows():\n",
    "        if row.class_id == str(k):\n",
    "            i+=1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100578</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103494</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>93885</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>95890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>96662</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>97302</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>99431</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>826 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id class_id\n",
       "0     100578        2\n",
       "1      10079        1\n",
       "2     102385        0\n",
       "3      10264        0\n",
       "4     103494        5\n",
       "..       ...      ...\n",
       "821    93885        7\n",
       "822    95890        1\n",
       "823    96662        5\n",
       "824    97302        4\n",
       "825    99431        6\n",
       "\n",
       "[826 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('results.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
